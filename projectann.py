# -*- coding: utf-8 -*-
"""ProjectANN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10sBa6g5GYnihqxWOIuhfDAJQGiLT2IOj
"""

import warnings
warnings.filterwarnings('ignore')


import pandas as pd






from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler,LabelEncoder
from sklearn.metrics import accuracy_score
import pickle

# load the dataset
data=pd.read_csv('/content/Churn_Modelling.csv')
data.head()

data=data.drop(['RowNumber','CustomerId','Surname'],axis=1)

data.head()

label_encoder_gender=LabelEncoder()
data['Gender']=label_encoder_gender.fit_transform(data['Gender'])

data

#one hot encoder
from sklearn.preprocessing import OneHotEncoder
onehot_encoder_geo=OneHotEncoder(sparse_output=False)
geo_encoder=onehot_encoder_geo.fit_transform(data[['Geography']])
geo_encoder=pd.DataFrame(geo_encoder,columns=['Germany','France','Spain'])

geo_encoder.to_xarray()

onehot_encoder_geo.get_feature_names_out(['Geography'])

geo_encoded_df=pd.DataFrame(geo_encoder.values,columns=onehot_encoder_geo.get_feature_names_out(['Geography']))

geo_encoded_df

data=data.drop(['Geography'],axis=1)

data

"""It appears the one-hot encoded geography columns were added multiple times. I will remove the duplicate columns, keeping only the first occurrence of each."""

# Drop duplicate columns, keeping the first occurrence
data = data.loc[:,~data.columns.duplicated()]

# Display the cleaned DataFrame
display(data.head())

#save the encoders and scaler
pickle.dump(label_encoder_gender,open('gender_encoder.pkl','wb'))
pickle.dump(onehot_encoder_geo,open('geo_encoder.pkl','wb'))
pickle.dump(StandardScaler(),open('scaler.pkl','wb'))

# devide dataset into independent and dependent features
X=data.drop('Exited',axis=1)
y=data['Exited']
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)
scaler=StandardScaler()
X_train=scaler.fit_transform(X_train)
X_test=scaler.transform(X_test)

X_train

with open('scaler.pkl', 'wb') as file:
    pickle.dump(scaler, file)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.callbacks import EarlyStopping,TensorBoard

# build an ANN Model
model=Sequential()
model.add(Dense(64,activation='relu',input_dim=X_train.shape[1]))
model.add(Dense(32,activation='relu'))
model.add(Dense(1,activation='sigmoid'))

model.summary()

model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])

opt=tf.optimizers.Adam(learning_rate=0.001)
loss=tf.keras.losses.BinaryCrossentropy()
loss

model.compile(optimizer=opt,loss="binary_crossentropy",metrics=['accuracy'])

import datetime
log_dir='logs/fit'+datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
tensorboard_callback=TensorBoard(log_dir=log_dir,histogram_freq=1)

early_stop=EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=50,restore_best_weights=True)

history=model.fit(X_train,y_train,epochs=100,validation_data=(X_test,y_test),callbacks=[early_stop,tensorboard_callback])

model.save('churn_model.h5')

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir /content/logs/fit20260112-113846

#load the pickle file
with open('scaler.pkl', 'rb') as file:
    scaler = pickle.load(file)

with open('gender_encoder.pkl', 'rb') as file:
    gender_encoder = pickle.load(file)

with open('geo_encoder.pkl', 'rb') as file:
    geo_encoder = pickle.load(file)

from tensorflow.keras.models import load_model
model=load_model('churn_model.h5')

input_date={'CreditScore':600,'Geography':'France','Gender':'Male','Age':42,'Tenure':3,'Balance':60000.0,'NumOfProducts':2,'HasCrCard':1,'IsActiveMember':1,'EstimatedSalary':50000}

geo_encoded=geo_encoder.transform([[input_date['Geography']]])

geo_encoded_df=pd.DataFrame(geo_encoded,columns=geo_encoder.get_feature_names_out(['Geography']))

geo_encoded_df

input_date=pd.concat([pd.DataFrame(input_date,index=[0]),geo_encoded_df],axis=1)

input_date

input_date['Gender']=label_encoder_gender.transform(input_date['Gender'])

input_date

input_date.drop('Geography',axis=1, inplace=True)

input_date

input_scaled=scaler.transform(input_date)
input_scaled

prediction=model.predict(input_scaled)

prediction

prediction_proba=prediction[0][0]
prediction_proba

if prediction_proba>0.5:
  print('the customer is likely to churn')
else:
  print('the customer is not likely to churn')

